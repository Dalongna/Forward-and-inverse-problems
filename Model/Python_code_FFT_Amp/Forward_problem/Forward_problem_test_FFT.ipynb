{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "Data_path = '/home/ubuntu/data/workspace/Li/Data/'\n",
    "save_path = '/home/ubuntu/data/workspace/Li/Model/Python_code_FFT_Amp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 9900\n",
    "batch_size = 1\n",
    "\n",
    "# 定义数据集类\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, generation_signals, labels, experimental_signal):\n",
    "        self.generation_signals = torch.tensor(generation_signals, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.experimental_signal = torch.tensor(experimental_signal, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generation_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'generation_signal': self.generation_signals[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'experimental_signal': self.experimental_signal[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, signal_length, label_dim, output_shape, hidden_dim, dropout_rate):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # 输入信号处理路径（编码器部分）\n",
    "        self.encoder_signal = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=hidden_dim//4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//4, out_channels=hidden_dim//8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//8, out_channels=hidden_dim//16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 标签处理路径（MLP）\n",
    "        self.label_fc = nn.Sequential(\n",
    "            nn.Linear(label_dim, hidden_dim//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//4, hidden_dim//8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//8, hidden_dim//16)\n",
    "        )\n",
    "        \n",
    "        # 合并后的输出路径（解码器部分）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//16 + hidden_dim//16, out_channels=hidden_dim//8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//8, out_channels=hidden_dim//4, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//4, out_channels=1, kernel_size=6, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 最后的输出层\n",
    "        self.output_layer = nn.Linear(signal_length, output_shape)\n",
    "\n",
    "    def forward(self, signal, label):\n",
    "        # 处理信号 [batch, 1, signal_length]\n",
    "        signal_features = self.encoder_signal(signal)  # 编码后的特征 [batch, hidden_dim//16, signal_length // 8]\n",
    "        \n",
    "        # 处理标签 [batch, label_dim]\n",
    "        label_features = self.label_fc(label)  # [batch, hidden_dim//64]\n",
    "        \n",
    "        # 将标签特征扩展为与信号特征相同的长度\n",
    "        label_features = label_features.unsqueeze(2).repeat(1, 1, signal_features.size(2))\n",
    "        \n",
    "        # 合并特征 [batch, hidden_dim//16 + hidden_dim//64, signal_length // 8]\n",
    "        combined = torch.cat([signal_features, label_features], dim=1)\n",
    "\n",
    "        # 解码 [batch, 1, signal_length]\n",
    "        decoded = self.decoder(combined)\n",
    "        \n",
    "        # 输出 [batch, output_shape]\n",
    "        output = self.output_layer(decoded.view(decoded.size(0), -1))\n",
    "        return output.view(-1, 1, M)  # 保持输入输出形状一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(generation_signal_path, experimental_signal_path, M):\n",
    "    generation_signals = []  # 存储生成信号\n",
    "    labels = []  # 存储标签 (Force_label, HI_label, Distance_label, Time_label)\n",
    "    experimental_signals = []  # 存储输出参数\n",
    "    filenames = []  # 存储文件名\n",
    "\n",
    "    # 加载生成信号数据\n",
    "    generation_dataPaths = sorted(glob.glob(os.path.join(generation_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in generation_dataPaths:\n",
    "\n",
    "        filename = os.path.basename(dataPath)\n",
    "        parts = filename.split('_')\n",
    "        Force_label = float(parts[0])\n",
    "        HI_label = float(parts[1])\n",
    "        Distance_label = float(parts[3])\n",
    "        Time_label = float(parts[2])\n",
    "\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            generation_signal = data_1.iloc[N:N+M, 1].values\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 分别存储 generation_signal 和 labels\n",
    "        generation_signals.append(generation_signal)\n",
    "        labels.append([Force_label, HI_label, Distance_label, Time_label])\n",
    "        filenames.append(filename)\n",
    "\n",
    "    # 加载实验信号数据\n",
    "    experimental_dataPaths = sorted(glob.glob(os.path.join(experimental_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in experimental_dataPaths:\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        filename = os.path.basename(dataPath)\n",
    "\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            experimental_signal = data_1.iloc[N:N+M, 1].values\n",
    "            experimental_signals.append(experimental_signal)  # 将 experimental_signal 添加到对应的 outputs 元素中\n",
    "\n",
    "    # 确保 generation_signals、labels 和 outputs 的长度一致\n",
    "    if len(generation_signals) != len(experimental_signals) or len(labels) != len(experimental_signals):\n",
    "        print(\"Error: The number of inputs and outputs does not match.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    generation_signals = np.array(generation_signals, dtype=float)\n",
    "    labels = np.array(labels, dtype=float)\n",
    "    experimental_signals = np.array(experimental_signals, dtype=float)\n",
    "\n",
    "    return generation_signals, labels, experimental_signals, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signal_path = f'{Data_path}Hanning_signal_generation'\n",
    "experimental_signal_path = f'{Data_path}Hanning_Signal_Experiment(10000)'\n",
    "\n",
    "# 加载数据\n",
    "filenames = os.listdir(generation_signal_path)  # 假设两个文件夹的文件名是一一对应的\n",
    "\n",
    "# 控制加载的数据量\n",
    "n = 100  # 假设只加载 n% 的数据\n",
    "num_samples = int(len(filenames) * n / 100)\n",
    "sampled_filenames = random.sample(filenames, num_samples)\n",
    "\n",
    "# 根据采样的文件名加载数据\n",
    "# 假设 load_data 函数已经定义好\n",
    "generation_signals, labels, experimental_signal, filenames = load_data(generation_signal_path, experimental_signal_path, M)\n",
    "\n",
    "# 将所有数据打乱\n",
    "shuffled_indices = np.arange(len(generation_signals))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "generation_signals = generation_signals[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "experimental_signal = experimental_signal[shuffled_indices]\n",
    "\n",
    "# 随机划分训练集、验证集和测试集\n",
    "# 比例为 4:2:4，即 40% 训练集，20% 验证集，40% 测试集\n",
    "train_val_indices, test_indices = train_test_split(range(len(sampled_filenames)), test_size=0.4)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.166)  # 20% / (40% + 20%) = 1/3\n",
    "\n",
    "# 提取测试集的文件名\n",
    "test_filenames = [sampled_filenames[i] for i in test_indices]\n",
    "\n",
    "# 其余代码保持不变\n",
    "generation_signals_train = generation_signals[train_indices]\n",
    "labels_train = labels[train_indices]\n",
    "experimental_signal_train = experimental_signal[train_indices]\n",
    "\n",
    "generation_signals_val = generation_signals[val_indices]\n",
    "labels_val = labels[val_indices]\n",
    "experimental_signal_val = experimental_signal[val_indices]\n",
    "\n",
    "generation_signals_test = generation_signals[test_indices]\n",
    "labels_test = labels[test_indices]\n",
    "experimental_signal_test = experimental_signal[test_indices]\n",
    "\n",
    "# 增加一个维度，从 [batch_size, N] 变为 [batch_size, 1, N]\n",
    "generation_signals_train = np.expand_dims(generation_signals_train, axis=1)\n",
    "experimental_signal_train = np.expand_dims(experimental_signal_train, axis=1)\n",
    "\n",
    "generation_signals_val = np.expand_dims(generation_signals_val, axis=1)\n",
    "experimental_signal_val = np.expand_dims(experimental_signal_val, axis=1)\n",
    "\n",
    "generation_signals_test = np.expand_dims(generation_signals_test, axis=1)\n",
    "experimental_signal_test = np.expand_dims(experimental_signal_test, axis=1)\n",
    "\n",
    "print(f'generation_signals_train:{generation_signals_train.shape}')\n",
    "print(f'generation_signals_val:{generation_signals_val.shape}')\n",
    "print(f'generation_signals_test:{generation_signals_test.shape}')\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = SignalDataset(generation_signals_train, labels_train, experimental_signal_train)\n",
    "val_dataset = SignalDataset(generation_signals_val, labels_val, experimental_signal_val)\n",
    "test_dataset = SignalDataset(generation_signals_test, labels_test, experimental_signal_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signals_test_1 = generation_signals_test.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(generation_signals_test_1[1],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(v)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/Generation_signal_test.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_signal_test_1 = experimental_signal_test.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(experimental_signal_test_1[25],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(V)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/Experiment_signal_test.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model=torch.load(f'{save_path}Forward_problem/Forward_Model.pth')  # 加载训练好的模型参数\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fft(signal, sampling_rate):\n",
    "    N = len(signal)  # 信号长度\n",
    "    fft_values = np.fft.fft(signal)  # 计算FFT\n",
    "    fft_magnitude = np.abs(fft_values)  # 取模\n",
    "    fft_magnitude = fft_magnitude[:N // 2]  # 只取一半（正频率部分）\n",
    "    freq = np.fft.fftfreq(N, d=1 / sampling_rate)[:N // 2]  # 频率轴\n",
    "    return freq, fft_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pcc(x, y):\n",
    "    \"\"\"\n",
    "    计算两个信号的皮尔逊相关系数(PCC)。\n",
    "\n",
    "    参数:\n",
    "        x (torch.Tensor): 第一个信号，假定在 CUDA 上。\n",
    "        y (torch.Tensor): 第二个信号，假定在 CUDA 上。\n",
    "\n",
    "    返回:\n",
    "        float: 皮尔逊相关系数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    \n",
    "    # 计算协方差\n",
    "    covariance = torch.mean((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_x = torch.std(x)\n",
    "    std_y = torch.std(y)\n",
    "    \n",
    "    # 计算皮尔逊相关系数\n",
    "    if std_x == 0 or std_y == 0:\n",
    "        raise ValueError(\"标准差不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    pcc = covariance / (std_x * std_y)\n",
    "\n",
    "    pcc_1 = pcc.to(device)\n",
    "\n",
    "    return pcc_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_time = 0.0\n",
    "pcc_fft = 0.0\n",
    "\n",
    "Error_fft = 0.0\n",
    "\n",
    "# 采样率\n",
    "sampling_rate = 2.5e7\n",
    "\n",
    "signal_predicted = []\n",
    "signal_origin=[]\n",
    "\n",
    "running_loss = 0.0\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()  \n",
    "# 进行预测\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for batch in test_loader:\n",
    "        generation_signal = batch['generation_signal'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        experimental_signal = batch['experimental_signal'].to(device)\n",
    "\n",
    "        experimental_signal_pred = model(generation_signal, labels)\n",
    "        loss = criterion(experimental_signal_pred, experimental_signal)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pcc_time += calculate_pcc(experimental_signal_pred,experimental_signal)\n",
    "\n",
    "        # 将重构信号移动到CPU并转换为NumPy数组\n",
    "        Origin_x3 = experimental_signal.cpu().numpy().squeeze()\n",
    "        predicted_x3 = experimental_signal_pred.cpu().numpy().squeeze()\n",
    "\n",
    "        # 假设 Original_signal 和 predicted_signal 已经定义\n",
    "        freq_origin, fft_magnitude_origin = calculate_fft(Origin_x3, sampling_rate)\n",
    "        freq_predicted, fft_magnitude_predicted = calculate_fft(predicted_x3, sampling_rate)\n",
    "\n",
    "        fft_magnitude_predicted,fft_magnitude_origin=torch.from_numpy(fft_magnitude_predicted),torch.from_numpy(fft_magnitude_origin),\n",
    "\n",
    "        Error_fft += criterion(fft_magnitude_predicted,fft_magnitude_origin)\n",
    "        pcc_fft += calculate_pcc(fft_magnitude_predicted,fft_magnitude_origin)\n",
    "    \n",
    "        signal_origin.append(experimental_signal)\n",
    "        signal_predicted.append(experimental_signal_pred)\n",
    "\n",
    "    test_loss_time = running_loss / len(test_loader)\n",
    "    test_pcc_time = pcc_time / len(test_loader)\n",
    "\n",
    "    test_fft_error = Error_fft / len(test_loader)\n",
    "    test_fft_pcc = pcc_fft / len(test_loader)\n",
    "\n",
    "    print(f'Time_error:{test_loss_time:.4f}')\n",
    "    print(f'Time_PCC:{test_pcc_time:.4f}')\n",
    "    print(f'FFT_error:{test_fft_error:.4f}')\n",
    "    print(f'FFT_PCC:{test_fft_pcc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = os.path.join(Data_path, \"Results_MSE/Predicted_signal/\")\n",
    "\n",
    "# 检查目录是否存在\n",
    "if os.path.exists(results_1):\n",
    "    # 遍历目录中的所有文件\n",
    "    for filename in os.listdir(results_1):\n",
    "        file_path = os.path.join(results_1, filename)\n",
    "        try:\n",
    "            # 如果是文件，则删除\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(f\"The directory {results_1} does not exist.\")\n",
    "\n",
    "results_2 = os.path.join(Data_path, \"Results_MSE/Predicted_FFT/\")\n",
    "\n",
    "# 检查目录是否存在\n",
    "if os.path.exists(results_2):\n",
    "    # 遍历目录中的所有文件\n",
    "    for filename in os.listdir(results_2):\n",
    "        file_path = os.path.join(results_2, filename)\n",
    "        try:\n",
    "            # 如果是文件，则删除\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(f\"The directory {results_2} does not exist.\")\n",
    "\n",
    "results_3 = os.path.join(Data_path, \"Results_MSE/Time_Difference/\")\n",
    "\n",
    "# 检查目录是否存在\n",
    "if os.path.exists(results_3):\n",
    "    # 遍历目录中的所有文件\n",
    "    for filename in os.listdir(results_3):\n",
    "        file_path = os.path.join(results_3, filename)\n",
    "        try:\n",
    "            # 如果是文件，则删除\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "else:\n",
    "    print(f\"The directory {results_3} does not exist.\")\n",
    "\n",
    "# 定义文件名\n",
    "file_name = f'{save_path}Forward_problem/Test_Error_Amp.csv'\n",
    "\n",
    "# 检查文件是否存在，如果存在则删除\n",
    "file_path = os.path.join(save_path, file_name)\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 寻找指定频率范围内的最大幅值\n",
    "def find_max_in_range(freq, magnitude, freq_range):\n",
    "    mask = (freq / 1e3 >= freq_range[0]) & (freq / 1e3 <= freq_range[1])\n",
    "    max_index = np.argmax(magnitude[mask])\n",
    "    max_freq = freq[mask][max_index] / 1e3\n",
    "    max_magnitude = magnitude[mask][max_index]\n",
    "    return max_freq, max_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每个信号\n",
    "for a in range(len(experimental_signal_test)):\n",
    "    # 获取对应的 CSV 文件名\n",
    "    csv_filename = test_filenames[a]\n",
    "    # 去掉 CSV 文件名的扩展名，用于保存图片\n",
    "    csv_filename_without_extension = os.path.splitext(csv_filename)[0]\n",
    "\n",
    "    # 将重构信号移动到CPU并转换为NumPy数\n",
    "    signal_origin_3 = signal_origin[a].cpu().numpy().squeeze()\n",
    "    predicted_signal = signal_predicted[a].cpu().numpy().squeeze()\n",
    "\n",
    "    # 计算信号的差值\n",
    "    difference = signal_origin_3 - predicted_signal\n",
    "    Time_RMSE = np.sqrt(np.mean((signal_origin_3 - predicted_signal) ** 2))\n",
    "\n",
    "    # 采样率\n",
    "    sampling_rate = 2.5e7\n",
    "\n",
    "    # 假设 Original_signal 和 predicted_signal 已经定义\n",
    "    freq_origin, fft_magnitude_origin = calculate_fft(signal_origin_3, sampling_rate)\n",
    "    freq_predicted, fft_magnitude_predicted = calculate_fft(predicted_signal, sampling_rate)\n",
    "    fft_magnitude_predicted, fft_magnitude_origin = torch.from_numpy(fft_magnitude_predicted)*1e-4, torch.from_numpy(fft_magnitude_origin)*1e-4\n",
    "\n",
    "    # 绘制时域信号图\n",
    "    plt.style.use('default')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams['font.family'] = ['Times New Roman']\n",
    "    plt.plot(signal_origin_3, linewidth=1.5, label='Experimental Signal')\n",
    "    plt.plot(predicted_signal, linewidth=1.5, linestyle='--', label='Predicted Signal')\n",
    "\n",
    "    plt.xlabel('Sample point', fontdict={'weight': 'normal', 'size': 18})\n",
    "    plt.ylabel('Amplitude(V)', fontdict={'weight': 'normal', 'size': 18})\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    plt.text(max(signal_origin_3), max(signal_origin_3), f'RMSE = {Time_RMSE:.4f}', fontsize=28, verticalalignment='top')\n",
    "    plt.savefig(f'{Data_path}Results_FFT_Amp/Predicted_signal/{csv_filename_without_extension}.jpg', dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # 绘制差值图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.rcParams['font.family'] = ['Times New Roman']\n",
    "    plt.plot(difference, linewidth=1.5)\n",
    "    plt.xlim([0, M])\n",
    "    plt.ylim([-max(difference), max(difference)])\n",
    "\n",
    "    plt.xlabel('Sample point', fontdict={'weight': 'normal', 'size': 18})\n",
    "    plt.ylabel('Difference (V)', fontdict={'weight': 'normal', 'size': 18})\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    plt.savefig(f'{Data_path}Results_FFT_Amp/Time_Difference/{csv_filename_without_extension}.jpg', dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # 原始信号\n",
    "    A1_freq, Af = find_max_in_range(freq_origin, fft_magnitude_origin, (40, 60))\n",
    "    As_freq, As = find_max_in_range(freq_origin, fft_magnitude_origin, (80, 120))\n",
    "\n",
    "    # 预测信号\n",
    "    Bf_freq, Bf = find_max_in_range(freq_predicted, fft_magnitude_predicted, (40, 60))\n",
    "    Bs_freq, Bs = find_max_in_range(freq_predicted, fft_magnitude_predicted, (80, 120))\n",
    "\n",
    "    Af_max = max(Af,Bf)\n",
    "    As_max = max(As,Bs)\n",
    "\n",
    "    # 绘制FFT频谱图\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(freq_origin / 1e3, fft_magnitude_origin, label='Experimental Signal')\n",
    "    ax.plot(freq_predicted / 1e3, fft_magnitude_predicted, linestyle='--', label='Predicted Signal', color='orange')\n",
    "    ax.set_xlabel('Frequency (kHz)', fontdict={'weight': 'normal', 'size': 18})\n",
    "    ax.set_ylabel('FFT Magnitude', fontdict={'weight': 'normal', 'size': 18})\n",
    "    ax.legend()\n",
    "    ax.set_xlim([10, 120])\n",
    "    ax.set_ylim([0, Af_max])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.legend(loc='upper right', fontsize=20)\n",
    "\n",
    "    # 创建局部放大图\n",
    "    axins = inset_axes(ax, width=\"40%\", height=\"40%\", loc='lower left',\n",
    "                       bbox_to_anchor=(0.55, 0.1, 1, 1), bbox_transform=ax.transAxes, borderpad=1)\n",
    "    axins.plot(freq_origin / 1e3, fft_magnitude_origin, label='Experimental Signal')\n",
    "    axins.plot(freq_predicted / 1e3, fft_magnitude_predicted, linestyle='--', label='Predicted Signal', color='orange')\n",
    "    axins.set_xlim([80, 120])\n",
    "    axins.set_ylim([0, As_max])\n",
    "    axins.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    FFT_RMSE = torch.sqrt(torch.mean((fft_magnitude_origin - fft_magnitude_predicted) ** 2))\n",
    "    \n",
    "    # 计算NP_true和NP_pre\n",
    "    NP_true = As / (Af ** 2)\n",
    "    NP_pre = Bs / (Bf ** 2)\n",
    "\n",
    "    # 计算误差\n",
    "    NP_Error = abs(NP_true - NP_pre) / NP_true * 100\n",
    "\n",
    "    # 在图片中显示这些值\n",
    "    ax.text(0.05, 0.95, f'RMSE = {FFT_RMSE:.4f}\\nNP_true = {NP_true:.8f}\\nNP_pre = {NP_pre:.8f}\\nError = {NP_Error:.4f}%',\n",
    "            transform=ax.transAxes, fontsize=22, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    plt.savefig(f'{Data_path}Results_FFT_Amp/Predicted_FFT//{csv_filename_without_extension}.jpg', dpi=600, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"{csv_filename_without_extension}, {a+1}/{len(experimental_signal_test)}, NP_Error: {NP_Error:.4f}%, Time_RMSE = {Time_RMSE:.4f},FFT_RMSE = {FFT_RMSE:.8f}\")\n",
    "\n",
    "    # 打开 CSV 文件，如果文件不存在会自动创建\n",
    "    with open('Test_Error_Amp.csv', mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # 写入每一行的数据\n",
    "        writer.writerow([csv_filename_without_extension, f\"{a+1}/{len(experimental_signal_test)}\", f\"{NP_Error:.4f}\", f\"{Time_RMSE:.4f}\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "Data_path = '/home/ubuntu/data/workspace/Li/Data/'\n",
    "save_path = '/home/ubuntu/data/workspace/Li/Model/Python_code_FFT_Amp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 9900\n",
    "batch_size = 1\n",
    "\n",
    "# 定义数据集类\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, generation_signals, labels, experimental_signal):\n",
    "        self.generation_signals = torch.tensor(generation_signals, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.experimental_signal = torch.tensor(experimental_signal, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generation_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'generation_signal': self.generation_signals[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'experimental_signal': self.experimental_signal[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, signal_length, label_dim, output_shape, hidden_dim, dropout_rate):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # 输入信号处理路径（编码器部分）\n",
    "        self.encoder_signal = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=hidden_dim//4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//4, out_channels=hidden_dim//8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//8, out_channels=hidden_dim//16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 标签处理路径（MLP）\n",
    "        self.label_fc = nn.Sequential(\n",
    "            nn.Linear(label_dim, hidden_dim//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//4, hidden_dim//8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//8, hidden_dim//16)\n",
    "        )\n",
    "        \n",
    "        # 合并后的输出路径（解码器部分）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//16 + hidden_dim//16, out_channels=hidden_dim//8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//8, out_channels=hidden_dim//4, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//4, out_channels=1, kernel_size=6, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 最后的输出层\n",
    "        self.output_layer = nn.Linear(signal_length, output_shape)\n",
    "\n",
    "    def forward(self, signal, label):\n",
    "        # 处理信号 [batch, 1, signal_length]\n",
    "        signal_features = self.encoder_signal(signal)  # 编码后的特征 [batch, hidden_dim//16, signal_length // 8]\n",
    "        \n",
    "        # 处理标签 [batch, label_dim]\n",
    "        label_features = self.label_fc(label)  # [batch, hidden_dim//64]\n",
    "        \n",
    "        # 将标签特征扩展为与信号特征相同的长度\n",
    "        label_features = label_features.unsqueeze(2).repeat(1, 1, signal_features.size(2))\n",
    "        \n",
    "        # 合并特征 [batch, hidden_dim//16 + hidden_dim//64, signal_length // 8]\n",
    "        combined = torch.cat([signal_features, label_features], dim=1)\n",
    "\n",
    "        # 解码 [batch, 1, signal_length]\n",
    "        decoded = self.decoder(combined)\n",
    "        \n",
    "        # 输出 [batch, output_shape]\n",
    "        output = self.output_layer(decoded.view(decoded.size(0), -1))\n",
    "        return output.view(-1, 1, M)  # 保持输入输出形状一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(generation_signal_path, experimental_signal_path, M):\n",
    "    generation_signals = []  # 存储生成信号\n",
    "    labels = []  # 存储标签 (Force_label, HI_label, Distance_label, Time_label)\n",
    "    experimental_signals = []  # 存储输出参数\n",
    "    filenames = []  # 存储文件名\n",
    "\n",
    "    # 加载生成信号数据\n",
    "    generation_dataPaths = sorted(glob.glob(os.path.join(generation_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in generation_dataPaths:\n",
    "\n",
    "        filename = os.path.basename(dataPath)\n",
    "        parts = filename.split('_')\n",
    "        Force_label = float(parts[0])\n",
    "        HI_label = float(parts[1])\n",
    "        Distance_label = float(parts[3])\n",
    "        Time_label = float(parts[2])\n",
    "\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            generation_signal = data_1.iloc[N:N+M, 1].values\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 分别存储 generation_signal 和 labels\n",
    "        generation_signals.append(generation_signal)\n",
    "        labels.append([Force_label, HI_label, Distance_label, Time_label])\n",
    "        filenames.append(filename)\n",
    "\n",
    "    # 加载实验信号数据\n",
    "    experimental_dataPaths = sorted(glob.glob(os.path.join(experimental_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in experimental_dataPaths:\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        filename = os.path.basename(dataPath)\n",
    "\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            experimental_signal = data_1.iloc[N:N+M, 1].values\n",
    "            experimental_signals.append(experimental_signal)  # 将 experimental_signal 添加到对应的 outputs 元素中\n",
    "\n",
    "    # 确保 generation_signals、labels 和 outputs 的长度一致\n",
    "    if len(generation_signals) != len(experimental_signals) or len(labels) != len(experimental_signals):\n",
    "        print(\"Error: The number of inputs and outputs does not match.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    generation_signals = np.array(generation_signals, dtype=float)\n",
    "    labels = np.array(labels, dtype=float)\n",
    "    experimental_signals = np.array(experimental_signals, dtype=float)\n",
    "\n",
    "    return generation_signals, labels, experimental_signals, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signal_path = f'{Data_path}Hanning_signal_generation'\n",
    "experimental_signal_path = f'{Data_path}Hanning_Signal_Experiment(10000)'\n",
    "\n",
    "# 加载数据\n",
    "filenames = os.listdir(generation_signal_path)  # 假设两个文件夹的文件名是一一对应的\n",
    "\n",
    "# 控制加载的数据量\n",
    "n = 100  # 假设只加载 n% 的数据\n",
    "num_samples = int(len(filenames) * n / 100)\n",
    "sampled_filenames = random.sample(filenames, num_samples)\n",
    "\n",
    "# 根据采样的文件名加载数据\n",
    "# 假设 load_data 函数已经定义好\n",
    "generation_signals, labels, experimental_signal, filenames = load_data(generation_signal_path, experimental_signal_path, M)\n",
    "\n",
    "# 将所有数据打乱\n",
    "shuffled_indices = np.arange(len(generation_signals))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "generation_signals = generation_signals[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "experimental_signal = experimental_signal[shuffled_indices]\n",
    "\n",
    "test_filenames = [filename for filename in filenames]\n",
    "\n",
    "generation_signals_test = generation_signals\n",
    "labels_test = labels\n",
    "experimental_signal_test = experimental_signal\n",
    "\n",
    "generation_signals_test = np.expand_dims(generation_signals_test, axis=1)\n",
    "experimental_signal_test = np.expand_dims(experimental_signal_test, axis=1)\n",
    "\n",
    "print(f'generation_signals_test:{generation_signals_test.shape}')\n",
    "\n",
    "# 创建数据集\n",
    "test_dataset = SignalDataset(generation_signals_test, labels_test, experimental_signal_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signals_test_1 = generation_signals_test.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(generation_signals_test_1[1],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(v)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/Generation_signal_test.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_signal_test_1 = experimental_signal_test.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(experimental_signal_test_1[25],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(V)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/Experiment_signal_test.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "model=torch.load(f'{save_path}Forward_problem/Forward_Model.pth')  # 加载训练好的模型参数\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fft(signal, sampling_rate):\n",
    "    N = len(signal)  # 信号长度\n",
    "    fft_values = np.fft.fft(signal)  # 计算FFT\n",
    "    fft_magnitude = np.abs(fft_values)  # 取模\n",
    "    fft_magnitude = fft_magnitude[:N // 2]  # 只取一半（正频率部分）\n",
    "    freq = np.fft.fftfreq(N, d=1 / sampling_rate)[:N // 2]  # 频率轴\n",
    "    return freq, fft_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pcc(x, y):\n",
    "    \"\"\"\n",
    "    计算两个信号的皮尔逊相关系数(PCC)。\n",
    "\n",
    "    参数:\n",
    "        x (torch.Tensor): 第一个信号，假定在 CUDA 上。\n",
    "        y (torch.Tensor): 第二个信号，假定在 CUDA 上。\n",
    "\n",
    "    返回:\n",
    "        float: 皮尔逊相关系数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    \n",
    "    # 计算协方差\n",
    "    covariance = torch.mean((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_x = torch.std(x)\n",
    "    std_y = torch.std(y)\n",
    "    \n",
    "    # 计算皮尔逊相关系数\n",
    "    if std_x == 0 or std_y == 0:\n",
    "        raise ValueError(\"标准差不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    pcc = covariance / (std_x * std_y)\n",
    "\n",
    "    pcc_1 = pcc.to(device)\n",
    "\n",
    "    return pcc_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_time = 0.0\n",
    "pcc_fft = 0.0\n",
    "\n",
    "Error_fft = 0.0\n",
    "\n",
    "# 采样率\n",
    "sampling_rate = 2.5e7\n",
    "\n",
    "signal_predicted = []\n",
    "signal_origin=[]\n",
    "\n",
    "running_loss = 0.0\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# 将模型设置为评估模式\n",
    "model.eval()  \n",
    "# 进行预测\n",
    "with torch.no_grad():  # 关闭梯度计算\n",
    "    for batch in test_loader:\n",
    "        generation_signal = batch['generation_signal'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        experimental_signal = batch['experimental_signal'].to(device)\n",
    "\n",
    "        experimental_signal_pred = model(generation_signal, labels)\n",
    "        loss = criterion(experimental_signal_pred, experimental_signal)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pcc_time += calculate_pcc(experimental_signal_pred,experimental_signal)\n",
    "\n",
    "        # 将重构信号移动到CPU并转换为NumPy数组\n",
    "        Origin_x3 = experimental_signal.cpu().numpy().squeeze()\n",
    "        predicted_x3 = experimental_signal_pred.cpu().numpy().squeeze()\n",
    "\n",
    "        # 假设 Original_signal 和 predicted_signal 已经定义\n",
    "        freq_origin, fft_magnitude_origin = calculate_fft(Origin_x3, sampling_rate)\n",
    "        freq_predicted, fft_magnitude_predicted = calculate_fft(predicted_x3, sampling_rate)\n",
    "\n",
    "        fft_magnitude_predicted,fft_magnitude_origin=torch.from_numpy(fft_magnitude_predicted),torch.from_numpy(fft_magnitude_origin),\n",
    "\n",
    "        Error_fft += criterion(fft_magnitude_predicted,fft_magnitude_origin)\n",
    "        pcc_fft += calculate_pcc(fft_magnitude_predicted,fft_magnitude_origin)\n",
    "    \n",
    "        signal_origin.append(experimental_signal)\n",
    "        signal_predicted.append(experimental_signal_pred)\n",
    "\n",
    "    test_loss_time = running_loss / len(test_loader)\n",
    "    test_pcc_time = pcc_time / len(test_loader)\n",
    "\n",
    "    test_fft_error = Error_fft / len(test_loader)\n",
    "    test_fft_pcc = pcc_fft / len(test_loader)\n",
    "\n",
    "    print(f'Time_error:{test_loss_time:.4f}')\n",
    "    print(f'Time_PCC:{test_pcc_time:.4f}')\n",
    "    print(f'FFT_error:{test_fft_error:.4f}')\n",
    "    print(f'FFT_PCC:{test_fft_pcc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f'{Data_path}Hanning_Signal_Experiment(10000)'  # 替换为你的文件夹路径\n",
    "file_names = [file_name for file_name in os.listdir(folder_path) if file_name.endswith(\".csv\")]\n",
    "\n",
    "for a in range(0, len(file_names), 1):\n",
    "    file_name = file_names[a]  # 获取对应的文件名\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    # 假设 experimental_signals, signal_origin, signal_predicted 已定义\n",
    "    \n",
    "    # 将重构信号移动到CPU并转换为NumPy数\n",
    "    signal_origin_3 = signal_origin[a].cpu().numpy().squeeze()\n",
    "    predicted_signal = signal_predicted[a].cpu().numpy().squeeze()\n",
    "\n",
    "    # 保存 predicted_signal 到 CSV 文件\n",
    "    save_path = f'{Data_path}Prediction_signal_FFT_Amp'  # 保存路径\n",
    "    os.makedirs(save_path, exist_ok=True)  # 如果路径不存在，则创建\n",
    "    time = np.arange(len(predicted_signal)) * 4e-8  # 时间序列，起点为 0，间隔为 4e-8 秒\n",
    "    data_to_save = np.column_stack((time, predicted_signal))  # 将时间和信号合并为二维数组\n",
    "    np.savetxt(os.path.join(save_path, file_name), data_to_save, delimiter=',', header=\"Time(s),Amplitude(V)\", comments='')  # 保存为 CSV 文件\n",
    "    print(f\"Saved predicted signal to {os.path.join(save_path, file_name)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

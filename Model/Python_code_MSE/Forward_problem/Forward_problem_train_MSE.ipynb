{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import torch.fft\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA是否可用\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "Data_path = '/home/ubuntu/data/workspace/Li/Data/'\n",
    "save_path = '/home/ubuntu/data/workspace/Li/Model/Python_code_MSE/'\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 9900\n",
    "batch_size = 32\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# 定义数据集类\n",
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, generation_signals, labels, experimental_signal):\n",
    "        self.generation_signals = torch.tensor(generation_signals, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.experimental_signal = torch.tensor(experimental_signal, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.generation_signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'generation_signal': self.generation_signals[idx],\n",
    "            'labels': self.labels[idx],\n",
    "            'experimental_signal': self.experimental_signal[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, signal_length, label_dim, output_shape, hidden_dim, dropout_rate):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        \n",
    "        # 输入信号处理路径（编码器部分）\n",
    "        self.encoder_signal = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=hidden_dim//4, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//4, out_channels=hidden_dim//8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=hidden_dim//8, out_channels=hidden_dim//16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 标签处理路径（MLP）\n",
    "        self.label_fc = nn.Sequential(\n",
    "            nn.Linear(label_dim, hidden_dim//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//4, hidden_dim//8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//8, hidden_dim//16)\n",
    "        )\n",
    "        \n",
    "        # 合并后的输出路径（解码器部分）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//16 + hidden_dim//16, out_channels=hidden_dim//8, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//8, out_channels=hidden_dim//4, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=hidden_dim//4, out_channels=1, kernel_size=6, stride=2)\n",
    "        )\n",
    "        \n",
    "        # 最后的输出层\n",
    "        self.output_layer = nn.Linear(signal_length, output_shape)\n",
    "\n",
    "    def forward(self, signal, label):\n",
    "        # 处理信号 [batch, 1, signal_length]\n",
    "        signal_features = self.encoder_signal(signal)  # 编码后的特征 [batch, hidden_dim//16, signal_length // 8]\n",
    "        \n",
    "        # 处理标签 [batch, label_dim]\n",
    "        label_features = self.label_fc(label)  # [batch, hidden_dim//64]\n",
    "        \n",
    "        # 将标签特征扩展为与信号特征相同的长度\n",
    "        label_features = label_features.unsqueeze(2).repeat(1, 1, signal_features.size(2))\n",
    "        \n",
    "        # 合并特征 [batch, hidden_dim//16 + hidden_dim//64, signal_length // 8]\n",
    "        combined = torch.cat([signal_features, label_features], dim=1)\n",
    "\n",
    "        # 解码 [batch, 1, signal_length]\n",
    "        decoded = self.decoder(combined)\n",
    "        \n",
    "        # 输出 [batch, output_shape]\n",
    "        output = self.output_layer(decoded.view(decoded.size(0), -1))\n",
    "        return output.view(-1, 1, M)  # 保持输入输出形状一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(generation_signal_path, experimental_signal_path, M):\n",
    "    generation_signals = []  # 存储生成信号\n",
    "    labels = []  # 存储标签 (Force_label, HI_label, Distance_label, Time_label)\n",
    "    experimental_signals = []  # 存储输出参数\n",
    "    filenames = []  # 存储文件名\n",
    "\n",
    "    # 加载生成信号数据\n",
    "    generation_dataPaths = sorted(glob.glob(os.path.join(generation_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in generation_dataPaths:\n",
    "\n",
    "        filename = os.path.basename(dataPath)\n",
    "        parts = filename.split('_')\n",
    "        Force_label = float(parts[0])\n",
    "        HI_label = float(parts[1])\n",
    "        Distance_label = float(parts[3])\n",
    "        Time_label = float(parts[2])\n",
    "\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            generation_signal = data_1.iloc[N:N+M, 1].values\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # 分别存储 generation_signal 和 labels\n",
    "        generation_signals.append(generation_signal)\n",
    "        labels.append([Force_label, HI_label, Distance_label, Time_label])\n",
    "        filenames.append(filename)\n",
    "\n",
    "    # 加载实验信号数据\n",
    "    experimental_dataPaths = sorted(glob.glob(os.path.join(experimental_signal_path, '**', '*.csv'), recursive=True))\n",
    "    for dataPath in experimental_dataPaths:\n",
    "\n",
    "        data_1 = pd.read_csv(dataPath)\n",
    "        filename = os.path.basename(dataPath)\n",
    "\n",
    "        for N in range(len(data_1)):\n",
    "            if data_1.iloc[N, 1] != 0:\n",
    "                break\n",
    "        if N < len(data_1):\n",
    "            experimental_signal = data_1.iloc[N:N+M, 1].values\n",
    "            experimental_signals.append(experimental_signal)  # 将 experimental_signal 添加到对应的 outputs 元素中\n",
    "\n",
    "    # 确保 generation_signals、labels 和 outputs 的长度一致\n",
    "    if len(generation_signals) != len(experimental_signals) or len(labels) != len(experimental_signals):\n",
    "        print(\"Error: The number of inputs and outputs does not match.\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    # 转换为 NumPy 数组\n",
    "    generation_signals = np.array(generation_signals, dtype=float)\n",
    "    labels = np.array(labels, dtype=float)\n",
    "    experimental_signals = np.array(experimental_signals, dtype=float)\n",
    "\n",
    "    return generation_signals, labels, experimental_signals, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signal_path = f'{Data_path}Hanning_signal_generation'\n",
    "experimental_signal_path = f'{Data_path}Hanning_Signal_Experiment(10000)'\n",
    "\n",
    "# 加载数据\n",
    "filenames = os.listdir(generation_signal_path)  # 假设两个文件夹的文件名是一一对应的\n",
    "\n",
    "# 控制加载的数据量\n",
    "n = 100  # 假设只加载 n% 的数据\n",
    "num_samples = int(len(filenames) * n / 100)\n",
    "sampled_filenames = random.sample(filenames, num_samples)\n",
    "\n",
    "# 根据采样的文件名加载数据\n",
    "# 假设 load_data 函数已经定义好\n",
    "generation_signals, labels, experimental_signal, filenames = load_data(generation_signal_path, experimental_signal_path, M)\n",
    "\n",
    "# 将所有数据打乱\n",
    "shuffled_indices = np.arange(len(generation_signals))\n",
    "np.random.shuffle(shuffled_indices)\n",
    "\n",
    "generation_signals = generation_signals[shuffled_indices]\n",
    "labels = labels[shuffled_indices]\n",
    "experimental_signal = experimental_signal[shuffled_indices]\n",
    "\n",
    "# 随机划分训练集、验证集和测试集\n",
    "# 比例为 4:2:4，即 40% 训练集，20% 验证集，40% 测试集\n",
    "train_val_indices, test_indices = train_test_split(range(len(sampled_filenames)), test_size=0.4)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.166)  # 20% / (40% + 20%) = 1/3\n",
    "\n",
    "# 提取测试集的文件名\n",
    "test_filenames = [sampled_filenames[i] for i in test_indices]\n",
    "\n",
    "# 其余代码保持不变\n",
    "generation_signals_train = generation_signals[train_indices]\n",
    "labels_train = labels[train_indices]\n",
    "experimental_signal_train = experimental_signal[train_indices]\n",
    "\n",
    "generation_signals_val = generation_signals[val_indices]\n",
    "labels_val = labels[val_indices]\n",
    "experimental_signal_val = experimental_signal[val_indices]\n",
    "\n",
    "generation_signals_test = generation_signals[test_indices]\n",
    "labels_test = labels[test_indices]\n",
    "experimental_signal_test = experimental_signal[test_indices]\n",
    "\n",
    "# 增加一个维度，从 [batch_size, N] 变为 [batch_size, 1, N]\n",
    "generation_signals_train = np.expand_dims(generation_signals_train, axis=1)\n",
    "experimental_signal_train = np.expand_dims(experimental_signal_train, axis=1)\n",
    "\n",
    "generation_signals_val = np.expand_dims(generation_signals_val, axis=1)\n",
    "experimental_signal_val = np.expand_dims(experimental_signal_val, axis=1)\n",
    "\n",
    "generation_signals_test = np.expand_dims(generation_signals_test, axis=1)\n",
    "experimental_signal_test = np.expand_dims(experimental_signal_test, axis=1)\n",
    "\n",
    "print(f'generation_signals_train:{generation_signals_train.shape}')\n",
    "print(f'generation_signals_val:{generation_signals_val.shape}')\n",
    "print(f'generation_signals_test:{generation_signals_test.shape}')\n",
    "\n",
    "# 创建数据集\n",
    "train_dataset = SignalDataset(generation_signals_train, labels_train, experimental_signal_train)\n",
    "val_dataset = SignalDataset(generation_signals_val, labels_val, experimental_signal_val)\n",
    "test_dataset = SignalDataset(generation_signals_test, labels_test, experimental_signal_test)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_signals_train_1 = generation_signals_train.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(generation_signals_train_1[10],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(V)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/generation_signal.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_signal_train_1 = experimental_signal_train.reshape(-1,M,1)\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.rcParams['font.family'] = ['Times New Roman']\n",
    "plt.plot(experimental_signal_train_1[35],linewidth=1.5)\n",
    "plt.xlabel('Sample point',fontdict={'weight': 'normal', 'size': 18})\n",
    "plt.ylabel('Amplitude(V)',fontdict={'weight': 'normal', 'size': 18})\n",
    "#坐标轴刻度大小设置\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.xlim([0,M])\n",
    "plt.savefig(f'{save_path}Forward_problem/Experiment_signal.jpg', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pcc(x, y):\n",
    "    \"\"\"\n",
    "    计算两个信号的皮尔逊相关系数(PCC)。\n",
    "\n",
    "    参数:\n",
    "        x (torch.Tensor): 第一个信号，假定在 CUDA 上。\n",
    "        y (torch.Tensor): 第二个信号，假定在 CUDA 上。\n",
    "\n",
    "    返回:\n",
    "        float: 皮尔逊相关系数。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 计算均值\n",
    "    mean_x = torch.mean(x)\n",
    "    mean_y = torch.mean(y)\n",
    "    \n",
    "    # 计算协方差\n",
    "    covariance = torch.mean((x - mean_x) * (y - mean_y))\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_x = torch.std(x)\n",
    "    std_y = torch.std(y)\n",
    "    \n",
    "    # 计算皮尔逊相关系数\n",
    "    if std_x == 0 or std_y == 0:\n",
    "        raise ValueError(\"标准差不能为零，这可能导致除以零的错误。\")\n",
    "    \n",
    "    pcc = covariance / (std_x * std_y)\n",
    "\n",
    "    pcc_1 = pcc.to(device)\n",
    "\n",
    "    return pcc_1.item()  # 将结果转换为 Python 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更简单的版本（如果你只需要幅值损失）\n",
    "def fft_difference(signal1, signal2, criterion=nn.MSELoss()):\n",
    "    \"\"\"\n",
    "    计算FFT幅值差异的简化版本\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size, _, N = signal1.shape\n",
    "    \n",
    "    # 计算FFT\n",
    "    fft1 = torch.fft.fft(signal1.squeeze(1), dim=-1)\n",
    "    fft2 = torch.fft.fft(signal2.squeeze(1), dim=-1)\n",
    "    \n",
    "    # 取前半部分并计算归一化幅值\n",
    "    amplitude1 = torch.abs(fft1[:, :N//2]) \n",
    "    amplitude2 = torch.abs(fft2[:, :N//2])\n",
    "    \n",
    "    # 计算损失\n",
    "    fft_loss = criterion(amplitude1, amplitude2)\n",
    "    \n",
    "    return fft_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1\n",
    "# 定义训练和验证函数\n",
    "def train_model(model, train_loader, val_loader, epochs, learning_rate, patience):\n",
    "    \"\"\"\n",
    "    :param model: 模型\n",
    "    :param train_loader: 训练数据加载器\n",
    "    :param val_loader: 验证数据加载器\n",
    "    :param epochs: 总训练轮数\n",
    "    :param learning_rate: 学习率\n",
    "    :param patience: 早停的耐心值，即在验证损失没有改善时等待的轮数\n",
    "    :return: 训练损失、验证损失、训练PCC、验证PCC、训练FFT、验证FFT\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_PCC = []\n",
    "    valid_PCC = []\n",
    "\n",
    "    train_FFT = []\n",
    "    valid_FFT = []\n",
    "\n",
    "    best_val_loss = float('inf')  # 初始化最佳验证损失为无穷大\n",
    "    best_epoch = 0  # 初始化最佳轮数\n",
    "    early_stopping_triggered = False  # 早停标志\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if early_stopping_triggered:\n",
    "            break  # 如果触发早停，则退出训练循环\n",
    "\n",
    "        train_PCC_2 = 0.0\n",
    "        train_FFT_2 = 0.0\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            generation_signal = batch['generation_signal'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            experimental_signal = batch['experimental_signal'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            experimental_signal_pred = model(generation_signal, labels)\n",
    "\n",
    "            FFT_Amp = fft_difference(experimental_signal_pred, experimental_signal)\n",
    "            train_FFT_2 += FFT_Amp.item()\n",
    "\n",
    "            PCC_1 = calculate_pcc(experimental_signal_pred, experimental_signal)\n",
    "            train_PCC_2 += PCC_1\n",
    "\n",
    "            loss = A * criterion(experimental_signal_pred, experimental_signal)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        train_mean_PCC = train_PCC_2 / len(train_loader)\n",
    "        train_PCC.append(train_mean_PCC)\n",
    "\n",
    "        train_loss_FFT = train_FFT_2 / len(train_loader)\n",
    "        train_FFT.append(train_loss_FFT)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        valid_PCC_2 = 0.0\n",
    "        valid_FFT_2 = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                generation_signal = batch['generation_signal'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                experimental_signal = batch['experimental_signal'].to(device)\n",
    "\n",
    "                experimental_signal_pred = model(generation_signal, labels)\n",
    "\n",
    "                PCC_1 = calculate_pcc(experimental_signal_pred, experimental_signal)\n",
    "                valid_PCC_2 += PCC_1\n",
    "\n",
    "                FFT_Amp = fft_difference(experimental_signal_pred, experimental_signal)\n",
    "                valid_FFT_2 += FFT_Amp.item()\n",
    "\n",
    "                loss = A * criterion(experimental_signal_pred, experimental_signal)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        valid_mean_PCC = valid_PCC_2 / len(val_loader)\n",
    "        valid_PCC.append(valid_mean_PCC)\n",
    "\n",
    "        valid_loss_FFT = valid_FFT_2 / len(val_loader)\n",
    "        valid_FFT.append(valid_loss_FFT)\n",
    "\n",
    "        # 检查是否需要早停\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            # 保存整个模型\n",
    "            torch.save(model, f'{save_path}Forward_problem/Forward_Model.pth')\n",
    "            patience_counter = 0  # 重置耐心计数器\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs. Best validation loss: {best_val_loss:.4f} at epoch {best_epoch + 1}.\")\n",
    "                early_stopping_triggered = True\n",
    "\n",
    "        if epoch % (epochs // 10) == 0:\n",
    "            print(f\"Epoch: {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\\n\"\n",
    "                  f\"train_loss_FFT: {train_loss_FFT:.8f}, valid_loss_FFT: {valid_loss_FFT:.8f}\\n\"\n",
    "                  f\"train_mean_PCC: {train_mean_PCC:.4f}, valid_mean_PCC: {valid_mean_PCC:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "epochs = 5000\n",
    "lr = 1e-4\n",
    "model = ConvAutoencoder(signal_length = M, label_dim = 4, output_shape = M, hidden_dim = 128, dropout_rate = 0.2).to(device)\n",
    "# 假设你已经定义了模型、训练数据加载器、验证数据加载器、损失函数等\n",
    "train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT = train_model(model, train_loader, val_loader, epochs=epochs, learning_rate=lr, patience = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_metrics(train_losses, val_losses, train_pccs, valid_pccs, train_ffts, valid_ffts, font='Times new roman', font_size=22, line_width=2):\n",
    "    \"\"\"\n",
    "    绘制训练和验证损失函数图,并同时绘制PCC和FFT值。\n",
    "\n",
    "    参数：\n",
    "    train_losses (list): 训练损失值列表。\n",
    "    val_losses (list): 验证损失值列表。\n",
    "    train_pccs (list): 训练PCC值列表。\n",
    "    valid_pccs (list): 验证PCC值列表。\n",
    "    train_ffts (list): 训练FFT值列表。\n",
    "    valid_ffts (list): 验证FFT值列表。\n",
    "    font (str): 字体，默认为 'Arial'。\n",
    "    font_size (int): 字号，默认为 12。\n",
    "    line_width (float): 线条粗细，默认为 2。\n",
    "    \"\"\"\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax1 = plt.gca()  # 获取当前主图的轴对象\n",
    "\n",
    "    # 绘制损失\n",
    "    ax1.plot(train_losses, label='Training Time-domain Loss', color='red', linewidth=line_width, marker='o')\n",
    "    ax1.plot(val_losses, label='Validation Time-domain Loss', color='red', linewidth=line_width, linestyle='--', marker='s')\n",
    "\n",
    "    # 设置主图的标签和标题\n",
    "    ax1.set_xlabel('Epochs', fontname=font, fontsize=font_size)\n",
    "    ax1.set_ylabel('Time-domain Loss', fontname=font, fontsize=font_size, color='red')\n",
    "    ax1.tick_params(axis='both', which='major',labelcolor='red', labelsize=font_size)\n",
    "\n",
    "    # 创建第二个Y轴\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(train_ffts, label='Training Frequency-domain Loss', color='green', linewidth=line_width, marker='o')\n",
    "    ax2.plot(valid_ffts, label='Validation Frequency-domain Loss', color='green', linewidth=line_width, linestyle='--', marker='s')\n",
    "    ax2.set_ylabel('Frequency-domain Loss', fontname=font, fontsize=font_size, color='green')\n",
    "    ax2.tick_params(axis='y', which='major',labelcolor='green', labelsize=font_size)\n",
    "\n",
    "    # 创建第三个Y轴\n",
    "    ax3 = ax1.twinx()\n",
    "    ax3.spines['right'].set_position(('outward', 80))  # 将第三个Y轴向右移动\n",
    "    ax3.plot(train_pccs, label='Training PCC', color='black', linewidth=line_width, marker='o')\n",
    "    ax3.plot(valid_pccs, label='Validation PCC', color='black', linewidth=line_width, linestyle='--', marker='s')\n",
    "    ax3.set_ylabel('PCC', fontname=font, fontsize=font_size, color='black')\n",
    "    ax3.tick_params(axis='y', which='major',labelcolor='black', labelsize=font_size)\n",
    "\n",
    "    # 将图例放在一起\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    lines3, labels3 = ax3.get_legend_handles_labels()\n",
    "    ax1.legend(lines + lines2 + lines3, labels + labels2 + labels3, loc=(0.1,0.2), fontsize=font_size)\n",
    "    \n",
    "    # 保存图像\n",
    "    plt.savefig(f'{save_path}Forward_problem/Forward_Model_Loss.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数，传入你的数据\n",
    "plot_loss_and_metrics(train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_metrics(train_losses, val_losses, train_pccs, valid_pccs, train_ffts, valid_ffts, font='Times new roman', font_size=22, line_width=2):\n",
    "    \"\"\"\n",
    "    绘制训练和验证损失函数图,并同时绘制PCC和FFT值。\n",
    "\n",
    "    参数：\n",
    "    train_losses (list): 训练损失值列表。\n",
    "    val_losses (list): 验证损失值列表。\n",
    "    train_pccs (list): 训练PCC值列表。\n",
    "    valid_pccs (list): 验证PCC值列表。\n",
    "    train_ffts (list): 训练FFT值列表。\n",
    "    valid_ffts (list): 验证FFT值列表。\n",
    "    font (str): 字体，默认为 'Arial'。\n",
    "    font_size (int): 字号，默认为 12。\n",
    "    line_width (float): 线条粗细，默认为 2。\n",
    "    \"\"\"\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax1 = plt.gca()  # 获取当前主图的轴对象\n",
    "\n",
    "    # 绘制损失\n",
    "    ax1.plot(train_losses, label='Training Time-domain Loss', color='red', linewidth=line_width, marker='o')\n",
    "    ax1.plot(val_losses, label='Validation Time-domain Loss', color='red', linewidth=line_width, linestyle='--', marker='s')\n",
    "  \n",
    "    y_min = min(min(train_losses[int(len(train_losses)*0.8):len(train_losses)]),min(val_losses[int(len(train_losses)*0.8):len(train_losses)]))\n",
    "    y_max = max(max(train_losses[int(len(train_losses)*0.8):len(train_losses)]),max(val_losses[int(len(train_losses)*0.8):len(train_losses)]))\n",
    "    # 设置主图的标签和标题\n",
    "    ax1.set_xlabel('Epochs', fontname=font, fontsize=font_size)\n",
    "    ax1.set_ylabel('Time-domain Loss', fontname=font, fontsize=font_size, color='red')\n",
    "    ax1.tick_params(axis='both', which='major',labelcolor='red', labelsize=font_size)\n",
    "    plt.xlim(int(len(train_losses)*0.8),len(train_losses))\n",
    "    plt.ylim(y_min,y_max)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(f'{save_path}Forward_problem/Model_Loss_Enlargement_Time.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数，传入你的数据\n",
    "plot_loss_and_metrics(train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_metrics(train_losses, val_losses, train_pccs, valid_pccs, train_ffts, valid_ffts, font='Times new roman', font_size=22, line_width=2):\n",
    "    \"\"\"\n",
    "    绘制训练和验证损失函数图,并同时绘制PCC和FFT值。\n",
    "\n",
    "    参数：\n",
    "    train_losses (list): 训练损失值列表。\n",
    "    val_losses (list): 验证损失值列表。\n",
    "    train_pccs (list): 训练PCC值列表。\n",
    "    valid_pccs (list): 验证PCC值列表。\n",
    "    train_ffts (list): 训练FFT值列表。\n",
    "    valid_ffts (list): 验证FFT值列表。\n",
    "    font (str): 字体，默认为 'Arial'。\n",
    "    font_size (int): 字号，默认为 12。\n",
    "    line_width (float): 线条粗细，默认为 2。\n",
    "    \"\"\"\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax1 = plt.gca()  # 获取当前主图的轴对象\n",
    "    ax1.plot(train_ffts, label='Training Frequency-domain Loss', color='green', linewidth=line_width, marker='o')\n",
    "    ax1.plot(valid_ffts, label='Validation Frequency-domain Loss', color='green', linewidth=line_width, linestyle='--', marker='s')\n",
    "    \n",
    "    y_min = min(min(train_ffts[int(len(train_ffts)*0.8):len(train_ffts)]),min(valid_ffts[int(len(valid_ffts)*0.8):len(valid_ffts)]))\n",
    "    y_max = max(max(train_ffts[int(len(train_ffts)*0.8):len(train_ffts)]),max(valid_ffts[int(len(valid_ffts)*0.8):len(valid_ffts)]))\n",
    "    \n",
    "    ax1.set_ylabel('Frequency-domain Loss', fontname=font, fontsize=font_size, color='green')\n",
    "    ax1.tick_params(axis='x', which='major',labelcolor='green', labelsize=font_size)\n",
    "    ax1.tick_params(axis='y', which='major',labelcolor='green', labelsize=font_size)\n",
    "    plt.xlim(int(len(train_ffts)*0.8),len(train_ffts))\n",
    "    plt.ylim(y_min,y_max)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(f'{save_path}Forward_problem/Model_Loss_Enlargement_Frequency.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数，传入你的数据\n",
    "plot_loss_and_metrics(train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_metrics(train_losses, val_losses, train_pccs, valid_pccs, train_ffts, valid_ffts, font='Times new roman', font_size=22, line_width=2):\n",
    "    \"\"\"\n",
    "    绘制训练和验证损失函数图,并同时绘制PCC和FFT值。\n",
    "\n",
    "    参数：\n",
    "    train_losses (list): 训练损失值列表。\n",
    "    val_losses (list): 验证损失值列表。\n",
    "    train_pccs (list): 训练PCC值列表。\n",
    "    valid_pccs (list): 验证PCC值列表。\n",
    "    train_ffts (list): 训练FFT值列表。\n",
    "    valid_ffts (list): 验证FFT值列表。\n",
    "    font (str): 字体，默认为 'Arial'。\n",
    "    font_size (int): 字号，默认为 12。\n",
    "    line_width (float): 线条粗细，默认为 2。\n",
    "    \"\"\"\n",
    "    # 创建主图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax1 = plt.gca()  # 获取当前主图的轴对象\n",
    "    ax1.plot(train_pccs, label='Training PCC', color='black', linewidth=line_width, marker='o')\n",
    "    ax1.plot(valid_pccs, label='Validation PCC', color='black', linewidth=line_width, linestyle='--', marker='s')\n",
    "\n",
    "    y_min = min(min(train_pccs[int(len(train_pccs)*0.8):len(train_pccs)]),min(valid_pccs[int(len(valid_pccs)*0.8):len(valid_pccs)]))\n",
    "    y_max = max(max(train_pccs[int(len(train_pccs)*0.8):len(train_pccs)]),max(valid_pccs[int(len(valid_pccs)*0.8):len(valid_pccs)]))\n",
    "\n",
    "    ax1.set_ylabel('PCC', fontname=font, fontsize=font_size, color='black')\n",
    "    ax1.tick_params(axis='x', which='major',labelcolor='black', labelsize=font_size)\n",
    "    ax1.tick_params(axis='y', which='major',labelcolor='black', labelsize=font_size)\n",
    "\n",
    "    plt.xlim(int(len(train_pccs)*0.8),len(train_pccs))\n",
    "    plt.ylim(y_min,y_max)\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(f'{save_path}Forward_problem/Model_Loss_Enlargement_PCC.jpg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数，传入你的数据\n",
    "plot_loss_and_metrics(train_losses, val_losses, train_PCC, valid_PCC, train_FFT, valid_FFT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
